{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Climate Data Visualization\n",
    "\n",
    "This notebook focuses on creating visualizations based on the processed and analyzed climate data. In a Databricks environment, these visualizations would typically be built using Databricks AI/BI Dashboards for interactivity. This notebook demonstrates how to generate key visualizations programmatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# In a real Databricks environment, we would use:\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"ClimateDataVisualization\").getOrCreate()\n",
    "\n",
    "# Define data directories - in Databricks these would typically be in DBFS\n",
    "PROCESSED_DIR = \"/dbfs/FileStore/climate_resilience/processed\"\n",
    "ANALYTICS_DIR = \"/dbfs/FileStore/climate_resilience/analytics\"\n",
    "VISUALIZATION_DIR = \"/dbfs/FileStore/climate_resilience/visualization\"\n",
    "os.makedirs(VISUALIZATION_DIR, exist_ok=True)\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "print(\"Climate Data Visualization environment initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data for Visualization\n",
    "\n",
    "This function loads the processed data and analytics results needed for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_for_visualization():\n",
    "    \"\"\"\n",
    "    Loads processed data and analytics results for visualization\n",
    "    \"\"\"\n",
    "    print(\"Loading data for visualization...\")\n",
    "    \n",
    "    data_dict = {}\n",
    "    \n",
    "    try:\n",
    "        # Load processed data (long and wide formats)\n",
    "        long_path = os.path.join(PROCESSED_DIR, \"climate_data_long.csv\")\n",
    "        wide_path = os.path.join(PROCESSED_DIR, \"climate_data_wide.csv\")\n",
    "        \n",
    "        if os.path.exists(long_path):\n",
    "            data_dict[\"long_data\"] = pd.read_csv(long_path)\n",
    "            print(f\"Loaded long format data from {long_path}\")\n",
    "        \n",
    "        if os.path.exists(wide_path):\n",
    "            data_dict[\"wide_data\"] = pd.read_csv(wide_path)\n",
    "            print(f\"Loaded wide format data from {wide_path}\")\n",
    "            \n",
    "        # Load analytics results\n",
    "        trend_path = os.path.join(ANALYTICS_DIR, \"trend_analysis_results.csv\")\n",
    "        corr_path = os.path.join(ANALYTICS_DIR, \"indicator_correlations.csv\")\n",
    "        future_path = os.path.join(ANALYTICS_DIR, \"future_predictions.csv\")\n",
    "        vuln_path = os.path.join(ANALYTICS_DIR, \"climate_vulnerability_index.csv\")\n",
    "        \n",
    "        if os.path.exists(trend_path):\n",
    "            data_dict[\"trend_results\"] = pd.read_csv(trend_path)\n",
    "            print(f\"Loaded trend analysis results from {trend_path}\")\n",
    "            \n",
    "        if os.path.exists(corr_path):\n",
    "            data_dict[\"correlation_matrix\"] = pd.read_csv(corr_path, index_col=0)\n",
    "            print(f\"Loaded correlation matrix from {corr_path}\")\n",
    "            \n",
    "        if os.path.exists(future_path):\n",
    "            data_dict[\"future_predictions\"] = pd.read_csv(future_path)\n",
    "            print(f\"Loaded future predictions from {future_path}\")\n",
    "            \n",
    "        if os.path.exists(vuln_path):\n",
    "            data_dict[\"vulnerability_index\"] = pd.read_csv(vuln_path)\n",
    "            print(f\"Loaded vulnerability index data from {vuln_path}\")\n",
    "            \n",
    "        if data_dict:\n",
    "            return data_dict\n",
    "        else:\n",
    "            print(\"No data files found for visualization\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data for visualization: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Executive Dashboard Visualizations\n",
    "\n",
    "This function generates key visualizations for an executive dashboard summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_executive_dashboard_visuals(data_dict):\n",
    "    \"\"\"\n",
    "    Generates key visualizations for an executive dashboard summary\n",
    "    \"\"\"\n",
    "    print(\"Creating executive dashboard visualizations...\")\n",
    "    \n",
    "    if data_dict is None:\n",
    "        print(\"No data for executive dashboard\")\n",
    "        return\n",
    "    \n",
    "    # Key Performance Indicators (KPIs)\n",
    "    kpis = {}\n",
    "    if \"vulnerability_index\" in data_dict and data_dict[\"vulnerability_index\"] is not None:\n",
    "        vuln_df = data_dict[\"vulnerability_index\"]\n",
    "        latest_vuln = vuln_df.iloc[-1][\"Climate_Vulnerability_Index\"]\n",
    "        kpis[\"Latest Vulnerability Index\"] = round(latest_vuln, 2)\n",
    "        \n",
    "    if \"trend_results\" in data_dict and data_dict[\"trend_results\"] is not None:\n",
    "        trend_df = data_dict[\"trend_results\"]\n",
    "        temp_trend = trend_df[trend_df[\"Indicator\"].str.contains(\"Temperature\")]\n",
    "        if not temp_trend.empty:\n",
    "            kpis[\"Avg Annual Temp Change (Â°C)\"] = round(temp_trend.iloc[0][\"Avg_Annual_Change\"], 3)\n",
    "            \n",
    "        co2_trend = trend_df[trend_df[\"Indicator\"].str.contains(\"CO2\")]\n",
    "        if not co2_trend.empty:\n",
    "            kpis[\"Avg Annual CO2 Change (tons/capita)\"] = round(co2_trend.iloc[0][\"Avg_Annual_Change\"], 3)\n",
    "            \n",
    "    print(f\"Executive KPIs: {kpis}\")\n",
    "    \n",
    "    # Create KPI visualization (using Plotly for better dashboard integration)\n",
    "    fig_kpi = go.Figure()\n",
    "    \n",
    "    domain_x = [0, 0.3, 0.6, 0.9]\n",
    "    for i, (key, value) in enumerate(kpis.items()):\n",
    "        fig_kpi.add_trace(go.Indicator(\n",
    "            mode = \"number\",\n",
    "            value = value,\n",
    "            title = {\"text\": key, \"font\": {\"size\": 14}},\n",
    "            domain = {\"x\": [domain_x[i], domain_x[i]+0.25], \"y\": [0, 1]},\n",
    "            number = {\"font\": {\"size\": 36}}\n",
    "        ))\n",
    "        \n",
    "    fig_kpi.update_layout(\n",
    "        title=\"Key Climate Resilience Indicators for Singapore\",\n",
    "        height=200,\n",
    "        margin=dict(l=20, r=20, t=50, b=20)\n",
    "    )\n",
    "    \n",
    "    kpi_path = os.path.join(VISUALIZATION_DIR, \"executive_kpis.html\")\n",
    "    fig_kpi.write_html(kpi_path)\n",
    "    print(f\"Saved KPI visualization to {kpi_path}\")\n",
    "    \n",
    "    # Create overall vulnerability trend plot\n",
    "    if \"vulnerability_index\" in data_dict and data_dict[\"vulnerability_index\"] is not None:\n",
    "        vuln_df = data_dict[\"vulnerability_index\"]\n",
    "        fig_vuln = px.line(vuln_df, x=\"Year_Numeric\", y=\"Climate_Vulnerability_Index\", \n",
    "                         title=\"Climate Vulnerability Index Trend for Singapore\",\n",
    "                         labels={\"Year_Numeric\": \"Year\", \"Climate_Vulnerability_Index\": \"Vulnerability Index\"})\n",
    "        fig_vuln.update_layout(hovermode=\"x unified\")\n",
    "        \n",
    "        vuln_trend_path = os.path.join(VISUALIZATION_DIR, \"vulnerability_trend.html\")\n",
    "        fig_vuln.write_html(vuln_trend_path)\n",
    "        print(f\"Saved vulnerability trend plot to {vuln_trend_path}\")\n",
    "        \n",
    "    # Create key indicator trends plot\n",
    "    if \"long_data\" in data_dict and data_dict[\"long_data\"] is not None:\n",
    "        df_long = data_dict[\"long_data\"]\n",
    "        key_indicators = [\"Average Temperature\", \"CO2 Emissions\", \"Rainfall\", \"Sea Level Rise\"]\n",
    "        df_key = df_long[df_long[\"Indicator\"].isin(key_indicators)]\n",
    "        \n",
    "        if not df_key.empty:\n",
    "            # Ensure Year is datetime\n",
    "            if df_key[\"Year\"].dtype != \"datetime64[ns]\":\n",
    "                 df_key[\"Year\"] = pd.to_datetime(df_key[\"Year\"].astype(str), format=\"%Y\")\n",
    "            \n",
    "            fig_trends = px.line(df_key, x=\"Year\", y=\"Value\", color=\"Indicator\", facet_row=\"Indicator\",\n",
    "                               title=\"Trends of Key Climate Indicators for Singapore\",\n",
    "                               labels={\"Year\": \"Year\", \"Value\": \"Indicator Value\"}, height=800)\n",
    "            fig_trends.update_yaxes(matches=None) # Allow different y-axis scales\n",
    "            fig_trends.update_layout(hovermode=\"x unified\")\n",
    "            \n",
    "            key_trends_path = os.path.join(VISUALIZATION_DIR, \"key_indicator_trends.html\")\n",
    "            fig_trends.write_html(key_trends_path)\n",
    "            print(f\"Saved key indicator trends plot to {key_trends_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Trend Analysis Dashboard Visualizations\n",
    "\n",
    "This function generates visualizations for a detailed trend analysis dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trend_dashboard_visuals(data_dict):\n",
    "    \"\"\"\n",
    "    Generates visualizations for a detailed trend analysis dashboard\n",
    "    \"\"\"\n",
    "    print(\"Creating trend analysis dashboard visualizations...\")\n",
    "    \n",
    "    if data_dict is None or \"long_data\" not in data_dict or \"trend_results\" not in data_dict:\n",
    "        print(\"Missing data for trend dashboard\")\n",
    "        return\n",
    "    \n",
    "    df_long = data_dict[\"long_data\"]\n",
    "    trend_df = data_dict[\"trend_results\"]\n",
    "    \n",
    "    # Ensure Year is datetime\n",
    "    if df_long[\"Year\"].dtype != \"datetime64[ns]\":\n",
    "        df_long[\"Year\"] = pd.to_datetime(df_long[\"Year\"].astype(str), format=\"%Y\")\n",
    "        \n",
    "    # Create interactive trend plot for all indicators\n",
    "    fig_all_trends = px.line(df_long, x=\"Year\", y=\"Value\", color=\"Indicator\",\n",
    "                           title=\"Detailed Trends of Climate Indicators for Singapore\",\n",
    "                           labels={\"Year\": \"Year\", \"Value\": \"Indicator Value\"})\n",
    "    fig_all_trends.update_layout(hovermode=\"x unified\")\n",
    "    \n",
    "    all_trends_path = os.path.join(VISUALIZATION_DIR, \"all_indicator_trends.html\")\n",
    "    fig_all_trends.write_html(all_trends_path)\n",
    "    print(f\"Saved detailed trends plot to {all_trends_path}\")\n",
    "    \n",
    "    # Create bar chart of average annual change\n",
    "    trend_df_sorted = trend_df.sort_values(\"Avg_Annual_Change\", ascending=False)\n",
    "    fig_annual_change = px.bar(trend_df_sorted, x=\"Indicator\", y=\"Avg_Annual_Change\",\n",
    "                             title=\"Average Annual Change by Climate Indicator\",\n",
    "                             labels={\"Indicator\": \"Climate Indicator\", \"Avg_Annual_Change\": \"Average Annual Change\"})\n",
    "    fig_annual_change.update_layout(xaxis_tickangle=-45)\n",
    "    \n",
    "    annual_change_path = os.path.join(VISUALIZATION_DIR, \"average_annual_change.html\")\n",
    "    fig_annual_change.write_html(annual_change_path)\n",
    "    print(f\"Saved average annual change plot to {annual_change_path}\")\n",
    "    \n",
    "    # Create scatter plot of R-squared vs Slope\n",
    "    fig_r2_slope = px.scatter(trend_df, x=\"Slope\", y=\"R_Squared\", color=\"Indicator\",\n",
    "                          hover_name=\"Indicator\", size=\"Total_Change\",\n",
    "                          title=\"Trend Strength (R-Squared) vs. Trend Magnitude (Slope)\",\n",
    "                          labels={\"Slope\": \"Trend Slope (Magnitude)\", \"R_Squared\": \"Trend Strength (R-Squared)\"})\n",
    "    \n",
    "    r2_slope_path = os.path.join(VISUALIZATION_DIR, \"r2_vs_slope.html\")\n",
    "    fig_r2_slope.write_html(r2_slope_path)\n",
    "    print(f\"Saved R-squared vs Slope plot to {r2_slope_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Predictive Dashboard Visualizations\n",
    "\n",
    "This function generates visualizations for a predictive dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_predictive_dashboard_visuals(data_dict):\n",
    "    \"\"\"\n",
    "    Generates visualizations for a predictive dashboard\n",
    "    \"\"\"\n",
    "    print(\"Creating predictive dashboard visualizations...\")\n",
    "    \n",
    "    if data_dict is None or \"long_data\" not in data_dict or \"future_predictions\" not in data_dict:\n",
    "        print(\"Missing data for predictive dashboard\")\n",
    "        return\n",
    "    \n",
    "    df_long = data_dict[\"long_data\"]\n",
    "    future_df = data_dict[\"future_predictions\"]\n",
    "    \n",
    "    # Ensure Year is datetime\n",
    "    if df_long[\"Year\"].dtype != \"datetime64[ns]\":\n",
    "        df_long[\"Year\"] = pd.to_datetime(df_long[\"Year\"].astype(str), format=\"%Y\")\n",
    "        \n",
    "    # Combine historical and future data\n",
    "    df_combined = pd.concat([\n",
    "        df_long[[\"Year\", \"Indicator\", \"Value\"]].rename(columns={\"Value\": \"Actual_Value\"}),\n",
    "        future_df[[\"Year\", \"Indicator\", \"Predicted_Value\"]].rename(columns={\"Year\": \"Year_Num\"})\n",
    "    ], ignore_index=True)\n",
    "    \n",
    "    # Convert future year num to datetime\n",
    "    df_combined[\"Year\"] = df_combined[\"Year\"].fillna(pd.to_datetime(df_combined[\"Year_Num\"], format=\"%Y\"))\n",
    "    df_combined = df_combined.drop(columns=[\"Year_Num\"])\n",
    "    \n",
    "    # Create interactive plot with historical data and future predictions\n",
    "    fig_predictions = go.Figure()\n",
    "    \n",
    "    indicators = df_combined[\"Indicator\"].unique()\n",
    "    \n",
    "    for indicator in indicators:\n",
    "        df_indicator = df_combined[df_combined[\"Indicator\"] == indicator]\n",
    "        \n",
    "        # Add historical trace\n",
    "        fig_predictions.add_trace(go.Scatter(\n",
    "            x=df_indicator[\"Year\"], \n",
    "            y=df_indicator[\"Actual_Value\"], \n",
    "            mode=\"lines+markers\", \n",
    "            name=f\"{indicator} (Historical)\",\n",
    "            visible=(indicator == indicators[0]) # Show first indicator by default\n",
    "        ))\n",
    "        \n",
    "        # Add prediction trace\n",
    "        fig_predictions.add_trace(go.Scatter(\n",
    "            x=df_indicator[\"Year\"], \n",
    "            y=df_indicator[\"Predicted_Value\"], \n",
    "            mode=\"lines\", \n",
    "            line=dict(dash=\"dash\"),\n",
    "            name=f\"{indicator} (Predicted)\",\n",
    "            visible=(indicator == indicators[0]) # Show first indicator by default\n",
    "        ))\n",
    "\n",
    "    # Create dropdown menu for indicator selection\n",
    "    buttons = []\n",
    "    for i, indicator in enumerate(indicators):\n",
    "        visibility = [False] * (len(indicators) * 2)\n",
    "        visibility[i*2] = True  # Historical trace\n",
    "        visibility[i*2+1] = True # Prediction trace\n",
    "        buttons.append(dict(\n",
    "            label=indicator,\n",
    "            method=\"update\",\n",
    "            args=[{\"visible\": visibility}, {\"title\": f\"Historical Data and Future Predictions: {indicator}\"}]\n",
    "        ))\n",
    "\n",
    "    fig_predictions.update_layout(\n",
    "        updatemenus=[dict(\n",
    "            active=0,\n",
    "            buttons=buttons,\n",
    "            direction=\"down\",\n",
    "            pad={\"r\": 10, \"t\": 10},\n",
    "            showactive=True,\n",
    "            x=0.1, xanchor=\"left\",\n",
    "            y=1.15, yanchor=\"top\"\n",
    "        )],\n",
    "        title=f\"Historical Data and Future Predictions: {indicators[0]}\",\n",
    "        xaxis_title=\"Year\",\n",
    "        yaxis_title=\"Indicator Value\",\n",
    "        hovermode=\"x unified\"\n",
    "    )\n",
    "    \n",
    "    predictions_path = os.path.join(VISUALIZATION_DIR, \"future_predictions_interactive.html\")\n",
    "    fig_predictions.write_html(predictions_path)\n",
    "    print(f\"Saved future predictions plot to {predictions_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Vulnerability Dashboard Visualizations\n",
    "\n",
    "This function generates visualizations for a vulnerability assessment dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vulnerability_dashboard_visuals(data_dict):\n",
    "    \"\"\"\n",
    "    Generates visualizations for a vulnerability assessment dashboard\n",
    "    \"\"\"\n",
    "    print(\"Creating vulnerability dashboard visualizations...\")\n",
    "    \n",
    "    if data_dict is None or \"vulnerability_index\" not in data_dict:\n",
    "        print(\"Missing data for vulnerability dashboard\")\n",
    "        return\n",
    "    \n",
    "    vuln_df = data_dict[\"vulnerability_index\"]\n",
    "    \n",
    "    # Ensure Year is datetime\n",
    "    if vuln_df[\"Year\"].dtype != \"datetime64[ns]\":\n",
    "        vuln_df[\"Year\"] = pd.to_datetime(vuln_df[\"Year\"].astype(str), format=\"%Y\")\n",
    "        \n",
    "    # Create vulnerability index trend plot (already created in executive dashboard, reuse)\n",
    "    vuln_trend_path = os.path.join(VISUALIZATION_DIR, \"vulnerability_trend.html\")\n",
    "    if not os.path.exists(vuln_trend_path):\n",
    "        fig_vuln = px.line(vuln_df, x=\"Year_Numeric\", y=\"Climate_Vulnerability_Index\", \n",
    "                         title=\"Climate Vulnerability Index Trend for Singapore\",\n",
    "                         labels={\"Year_Numeric\": \"Year\", \"Climate_Vulnerability_Index\": \"Vulnerability Index\"})\n",
    "        fig_vuln.update_layout(hovermode=\"x unified\")\n",
    "        fig_vuln.write_html(vuln_trend_path)\n",
    "        print(f\"Saved vulnerability trend plot to {vuln_trend_path}\")\n",
    "    \n",
    "    # Create component contribution plot (if components exist)\n",
    "    component_cols = [col for col in vuln_df.columns if \"_Norm\" in col]\n",
    "    if component_cols:\n",
    "        # Get latest year data\n",
    "        latest_year_data = vuln_df.iloc[-1]\n",
    "        component_values = latest_year_data[component_cols]\n",
    "        component_names = [col.replace(\"_Norm\", \"\") for col in component_cols]\n",
    "        \n",
    "        fig_components = px.bar(x=component_names, y=component_values.values,\n",
    "                              title=f\"Component Contributions to Vulnerability Index ({latest_year_data['Year_Numeric']})\",\n",
    "                              labels={\"x\": \"Component\", \"y\": \"Normalized Contribution\"})\n",
    "        \n",
    "        components_path = os.path.join(VISUALIZATION_DIR, \"vulnerability_components.html\")\n",
    "        fig_components.write_html(components_path)\n",
    "        print(f\"Saved vulnerability components plot to {components_path}\")\n",
    "        \n",
    "        # Create stacked area plot of component contributions over time\n",
    "        df_components_long = vuln_df.melt(id_vars=[\"Year\", \"Year_Numeric\"], value_vars=component_cols, \n",
    "                                          var_name=\"Component\", value_name=\"Contribution\")\n",
    "        df_components_long[\"Component\"] = df_components_long[\"Component\"].str.replace(\"_Norm\", \"\")\n",
    "        \n",
    "        fig_stacked_area = px.area(df_components_long, x=\"Year\", y=\"Contribution\", color=\"Component\",\n",
    "                                 title=\"Vulnerability Component Contributions Over Time\",\n",
    "                                 labels={\"Year\": \"Year\", \"Contribution\": \"Normalized Contribution\"})\n",
    "        fig_stacked_area.update_layout(hovermode=\"x unified\")\n",
    "        \n",
    "        stacked_area_path = os.path.join(VISUALIZATION_DIR, \"vulnerability_components_over_time.html\")\n",
    "        fig_stacked_area.write_html(stacked_area_path)\n",
    "        print(f\"Saved stacked area plot of components to {stacked_area_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function\n",
    "\n",
    "This function orchestrates the creation of all visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to orchestrate the creation of all visualizations\n",
    "    \"\"\"\n",
    "    print(f\"Starting visualization creation at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    # Load data\n",
    "    data_dict = load_data_for_visualization()\n",
    "    \n",
    "    if data_dict is not None:\n",
    "        # Create visualizations for different dashboards\n",
    "        create_executive_dashboard_visuals(data_dict)\n",
    "        create_trend_dashboard_visuals(data_dict)\n",
    "        create_predictive_dashboard_visuals(data_dict)\n",
    "        create_vulnerability_dashboard_visuals(data_dict)\n",
    "        \n",
    "        print(f\"Visualization creation completed at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(\"Visualizations are saved and ready for dashboard integration\")\n",
    "    else:\n",
    "        print(\"Visualization creation failed: No data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Visualization Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the visualization creation process\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
